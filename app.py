"""
æœŸæƒç­–ç•¥é‡åŒ–åˆ†æç³»ç»Ÿ v2.3.2
Flask ä¸»åº”ç”¨å…¥å£

ä¿®å¤å†…å®¹ï¼š
1. ç§»é™¤å¾ªç¯å¯¼å…¥é—®é¢˜
2. ä¿®æ­£å†å²è¯„åˆ†è·å–å‡½æ•°çš„ä½ç½®
3. ç¡®ä¿æ‰€æœ‰ä¾èµ–æ­£ç¡®å¯¼å…¥
4. å»é™¤ 18:00 æ—¶é—´é™åˆ¶ï¼Œé»˜è®¤è·å– OI æ•°æ®
"""
from flask import Flask, render_template, request, jsonify, send_from_directory, Response, stream_with_context
import json
import os
from typing import List, Dict, Any
from datetime import datetime
from collections import defaultdict
from core.market_data import get_vix_info, clear_vix_cache, get_vix_with_fallback
from storage.sqlite_repo import get_records_repo

from core import (
    DEFAULT_CFG,
    calculate_analysis,
    compute_linear_slope,
    map_slope_trend,
)
from core.futu_iv import fetch_iv_terms, estimate_iv_fetch_time
from core.futu_oi import batch_compute_delta_oi
app = Flask(__name__)
records_repo = get_records_repo()

# =========================
# æ—¶é—´åˆ¤æ–­å·¥å…·å‡½æ•°ï¼ˆå·²ç¦ç”¨æ—¶é—´é™åˆ¶ï¼‰
# =========================
def should_skip_oi_fetch() -> bool:
    """
    å§‹ç»ˆè¿”å› Falseï¼Œè¡¨ç¤ºä¸è·³è¿‡ OI æ•°æ®è·å–ã€‚
    """
    return False


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        if value is None or isinstance(value, bool):
            return default
        return float(value)
    except (TypeError, ValueError):
        return default


def _extract_score(record: Dict[str, Any], key: str, default: float = 0.0) -> float:
    """å…¼å®¹å†å² payload: ä¼˜å…ˆ analysis å­å¯¹è±¡ï¼Œå…¶æ¬¡å›é€€åˆ°é¡¶å±‚å­—æ®µã€‚"""
    if not isinstance(record, dict):
        return default

    analysis_payload = record.get('analysis', {})
    if isinstance(analysis_payload, dict):
        sub = analysis_payload.get(key)
        if sub is not None:
            return _safe_float(sub, default)

    top = record.get(key)
    if top is not None:
        return _safe_float(top, default)

    return default


def _count_valid_points(scores: List[float], n_days: int) -> int:
    if not scores or n_days <= 0:
        return 0
    valid = 0
    for score in scores:
        if score is None:
            continue
        try:
            float(score)
            valid += 1
        except (TypeError, ValueError):
            continue
        if valid >= n_days:
            break
    return valid


def _needs_trend_backfill(record: Dict[str, Any]) -> bool:
    """æ˜¯å¦éœ€è¦å¯¹å†å²è®°å½•è¡¥ç®—è¶‹åŠ¿å­—æ®µï¼ˆå…¼å®¹æ—§ payloadï¼‰ã€‚"""
    if not isinstance(record, dict):
        return False
    return (
        record.get("dir_slope_nd") is None
        or record.get("dir_trend_label") in (None, "")
        or record.get("trend_days_used") is None
    )


def enrich_records_with_trend_fields(records: List[Dict[str, Any]], cfg: Dict[str, Any]) -> List[Dict[str, Any]]:
    """æŒ‰ symbol+æ—¶é—´é¡ºåºè¡¥ç®—ç¼ºå¤±è¶‹åŠ¿å­—æ®µï¼Œé¿å…å†å²è®°å½•å‰ç«¯å±•ç¤ºä¸º 0ã€‚"""
    trend_days = int(cfg.get("trend_days", 5))

    # ä¿æŒåŸé¡ºåºï¼Œå…ˆæ„å»ºç´¢å¼•
    indexed = list(enumerate(records))
    by_symbol: Dict[str, List] = defaultdict(list)
    for idx, rec in indexed:
        symbol = (rec.get("symbol") or "").upper()
        by_symbol[symbol].append((idx, rec))

    out = list(records)
    for _symbol, items in by_symbol.items():
        # å‡åºéå†ï¼Œå½“å‰è®°å½•åªä½¿ç”¨â€œä¹‹å‰äº¤æ˜“æ—¥â€å†å²ï¼Œè´´è¿‘åœ¨çº¿åˆ†æè¯­ä¹‰
        items.sort(key=lambda x: x[1].get("timestamp", ""))
        prior_scores: List[float] = []

        for idx, rec in items:
            dir_score_now = _extract_score(rec, "direction_score", 0.0)

            if _needs_trend_backfill(rec):
                history_recent_first = list(reversed(prior_scores))
                slope = compute_linear_slope(history_recent_first, trend_days)
                out[idx]["dir_slope_nd"] = round(slope, 3)
                out[idx]["dir_trend_label"] = map_slope_trend(slope, cfg)
                out[idx]["trend_days_used"] = _count_valid_points(history_recent_first, trend_days)

            prior_scores.append(dir_score_now)

    return out


def get_history_scores(symbol: str, days: int = 5, as_of_date: str = None) -> List[float]:
    """
    è·å–æŒ‡å®šæ ‡çš„çš„å†å²æ–¹å‘è¯„åˆ†ï¼ˆç”¨äºè·¨æœŸä¸€è‡´æ€§è®¡ç®—ï¼‰
    
    v2.3.2 ä¿®å¤ç‰ˆæœ¬ï¼š
    - ä»"æœ€è¿‘ N æ¡è®°å½•"æ”¹ä¸º"æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥"
    - æ¯å¤©åªå–æœ€æ–°çš„ä¸€æ¡è®°å½•
    - å¢åŠ æ—¥æœŸæœ‰æ•ˆæ€§éªŒè¯
    
    Args:
        symbol: æ ‡çš„ä»£ç ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
        days: éœ€è¦çš„å†å²å¤©æ•°ï¼ˆé»˜è®¤ 5 å¤©ï¼‰
        as_of_date: æˆªæ­¢æ—¥æœŸï¼ˆæ ¼å¼: YYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
    Returns:
        å†å²è¯„åˆ†åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åºï¼Œæœ€æ–°åœ¨å‰ï¼‰
    """
    records = records_repo.list_records_by_symbol(symbol)
    symbol_upper = symbol.upper()
    
    # 1. ç­›é€‰è¯¥ symbol çš„æ‰€æœ‰è®°å½•
    symbol_records = [
        r for r in records 
        if r.get('symbol', '').upper() == symbol_upper
    ]
    
    if not symbol_records:
        return []
    
    # 2. ç¡®å®šæˆªæ­¢æ—¥æœŸ
    if as_of_date is None:
        as_of = datetime.now()
    else:
        try:
            as_of = datetime.strptime(as_of_date, '%Y-%m-%d')
        except ValueError:
            as_of = datetime.now()
    
    # 3. æŒ‰æ—¥æœŸåˆ†ç»„ï¼ˆæ¯å¤©åªä¿ç•™æœ€æ–°çš„ä¸€æ¡ï¼‰
    records_by_date = defaultdict(list)
    
    for r in symbol_records:
        timestamp = r.get('timestamp', '')
        if not timestamp:
            continue
        
        try:
            # æå–æ—¥æœŸéƒ¨åˆ† (YYYY-MM-DD)
            date_str = timestamp.split(' ')[0]
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            
            # åªè€ƒè™‘æˆªæ­¢æ—¥æœŸåŠä¹‹å‰çš„è®°å½•
            if dt <= as_of:
                records_by_date[date_str].append(r)
        except (ValueError, IndexError):
            continue
    
    # 4. æ¯å¤©åªä¿ç•™æœ€æ–°çš„è®°å½•ï¼ˆæŒ‰å®Œæ•´ timestamp æ’åºï¼‰
    daily_latest = {}
    for date_str, day_records in records_by_date.items():
        # æŒ‰æ—¶é—´æˆ³é™åºæ’åºï¼Œå–ç¬¬ä¸€æ¡ï¼ˆæœ€æ–°ï¼‰
        day_records.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        daily_latest[date_str] = day_records[0]
    
    # 5. æŒ‰æ—¥æœŸé™åºæ’åºï¼Œå–æœ€è¿‘ days
    sorted_dates = sorted(daily_latest.keys(), reverse=True)

    # 6. æå–æ–¹å‘è¯„åˆ†ï¼ˆæœ€å¤š days æ¡ï¼‰
    history_scores = []
    for date_str in sorted_dates[:days]:
        record = daily_latest[date_str]
        score = _extract_score(record, 'direction_score', 0.0)
        history_scores.append(score)

    return history_scores


def get_history_series(symbol: str, days: int = 5, as_of_date: str = None) -> Dict[str, List[float]]:
    """è·å–æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥çš„å†å²è¯„åˆ†åºåˆ—ï¼ˆæ–¹å‘+æ³¢åŠ¨ï¼‰ã€‚"""
    records = records_repo.list_records_by_symbol(symbol)
    symbol_upper = symbol.upper()

    symbol_records = [
        r for r in records
        if r.get('symbol', "").upper() == symbol_upper
    ]

    if not symbol_records:
        return {"direction": [], "vol": []}

    if as_of_date is None:
        as_of = datetime.now()
    else:
        try:
            as_of = datetime.strptime(as_of_date, "%Y-%m-%d")
        except ValueError:
            as_of = datetime.now()

    records_by_date = defaultdict(list)
    for r in symbol_records:
        timestamp = r.get("timestamp", "")
        if not timestamp:
            continue
        try:
            date_str = timestamp.split(" ")[0]
            dt = datetime.strptime(date_str, "%Y-%m-%d")
            if dt <= as_of:
                records_by_date[date_str].append(r)
        except (ValueError, IndexError):
            continue

    daily_latest = {}
    for date_str, day_records in records_by_date.items():
        day_records.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        daily_latest[date_str] = day_records[0]

    sorted_dates = sorted(daily_latest.keys(), reverse=True)
    direction_scores, vol_scores = [], []

    for date_str in sorted_dates[:days]:
        record = daily_latest[date_str]
        dir_score = _extract_score(record, "direction_score", 0.0)
        vol_score = _extract_score(record, "vol_score", 0.0)

        direction_scores.append(dir_score)
        vol_scores.append(vol_score)

    return {"direction": direction_scores, "vol": vol_scores}


# =========================
# Flask è·¯ç”±
# =========================
@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory('static', filename)


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """
    åˆ†ææ•°æ®æ¥å£
    
    POST /api/analyze?ignore_earnings=false
    Body: { "records": [...] }
    """
    try:
        ignore_earnings = request.args.get('ignore_earnings', 'false').lower() == 'true'
        records = request.json.get('records', [])
        
        if not isinstance(records, list):
            return jsonify({'error': 'æ•°æ®æ ¼å¼é”™è¯¯,éœ€è¦æ˜¯åˆ—è¡¨'}), 400
        
        if len(records) == 0:
            return jsonify({'error': 'æ•°æ®åˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
        
        # âœ¨ NEW: æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ç›˜åæ•°æ®è·å–
        skip_oi = should_skip_oi_fetch()
        skip_iv = skip_oi
        
        # æå–æ‰€æœ‰ symbol
        symbols = list(set(r.get('symbol', '') for r in records if r.get('symbol')))
        num_symbols = len(symbols)
        
        # åˆå§‹åŒ– IV / OI æ•°æ®å­—å…¸
        iv_data = {}
        oi_data = {}

        # åªè·å–ä¸€æ¬¡ VIXï¼Œé¿å…éšæ ‡çš„å¾ªç¯æ‰“å°
        vix_value = get_vix_with_fallback(default=18.0)

        if skip_iv:
            print(f"\nâ° å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ IV æ•°æ®è·å–")
        else:
            iv_estimated_time = estimate_iv_fetch_time(num_symbols)
            iv_estimated_minutes = iv_estimated_time / 60.0
            print(f"\n{'='*60}")
            print("[FUTU] æœŸæƒæ•°æ®:")
            print(f"   - æ ‡çš„æ•°é‡: {num_symbols}")
            print(f"   - é¢„è®¡è€—æ—¶: {iv_estimated_minutes:.1f} åˆ†é’Ÿ")
            print(f"{'='*60}\n")
            iv_data = fetch_iv_terms(symbols)

        if skip_oi:
            # âœ¨ è·³è¿‡ OI è·å–
            print(f"\nâ° å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ OI æ•°æ®è·å–")
            print(f"ğŸ“Š å°†ç›´æ¥åˆ†æ {num_symbols} ä¸ªæ ‡çš„ï¼ˆæ—  Î”OIï¼‰\n")
        else:
            oi_input = {
                symbol: iv_data.get(symbol).total_oi if iv_data.get(symbol) else None
                for symbol in symbols
            }
            oi_data = batch_compute_delta_oi(oi_input)
        
        results = []
        errors = []
        
        for i, record in enumerate(records):
            try:
                symbol = record.get('symbol', '')
                
                # æ³¨å…¥ IV æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                iv_result = iv_data.get(symbol)
                if iv_result:
                    if iv_result.iv7 is not None:
                        record['IV7'] = iv_result.iv7
                    if iv_result.iv30 is not None:
                        record['IV30'] = iv_result.iv30
                    if iv_result.iv60 is not None:
                        record['IV60'] = iv_result.iv60
                    if iv_result.iv90 is not None:
                        record['IV90'] = iv_result.iv90

                # æ³¨å…¥ OI æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                if not skip_oi and symbol in oi_data:
                    current_oi, delta_oi = oi_data[symbol]
                    record['oi_info'] = {
                        'total_oi': current_oi,
                        'delta_oi_1d': delta_oi,
                        'data_available': (current_oi is not None or delta_oi is not None),
                    }
                    if current_oi is not None:
                        record['TotalOI'] = current_oi
                    if delta_oi is not None:
                        record['Î”OI_1D'] = delta_oi
                        
                # è·å–å†å²è¯„åˆ†ç”¨äºè·¨æœŸä¸€è‡´æ€§è®¡ç®—ä¸æ–œç‡å åŠ 
                history_series = get_history_series(symbol, days=DEFAULT_CFG.get("trend_days", 5))
                history_scores = history_series["direction"]
                
                # âœ¨ NEW: ä¼ é€’ skip_oi æ ‡å¿—åˆ°åˆ†æå‡½æ•°
                analysis = calculate_analysis(
                    record,
                    ignore_earnings=ignore_earnings,
                    history_scores=history_scores,
                    skip_oi=skip_oi,  # âœ¨ æ–°å¢å‚æ•°
                    vix_value=vix_value
                )
                results.append(analysis)
            except Exception as e:
                error_msg = f"æ ‡çš„ {record.get('symbol', f'#{i+1}')} åˆ†æå¤±è´¥: {str(e)}"
                errors.append(error_msg)
                print(f"é”™è¯¯: {error_msg}")
        
        # ä¿å­˜æ•°æ®
        if results:
            records_repo.upsert_daily_latest(results)
        
        message = f'æˆåŠŸåˆ†æ {len(results)} ä¸ªæ ‡çš„'
        if errors:
            message += f',{len(errors)} ä¸ªå¤±è´¥'
        
        # âœ¨ ä¿®æ”¹å“åº”æ¶ˆæ¯
        if skip_oi:
            message += ' (å·²è·³è¿‡ OI æ•°æ®è·å–)'
        
        return jsonify({
            'message': message,
            'results': results,
            'errors': errors if errors else None,
            'oi_stats': {
                'total': num_symbols,
                'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                'with_delta': sum(1 for s in symbols if oi_data.get(s, (None, None))[1] is not None),
                'skipped': skip_oi  # âœ¨ æ–°å¢æ ‡å¿—
            }
        }), 201
    
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/records', methods=['GET'])
def get_records():
    """è·å–åˆ†æè®°å½•"""
    try:
        date_filter = request.args.get('date')
        quadrant_filter = request.args.get('quadrant')
        confidence_filter = request.args.get('confidence')
        data = records_repo.list_records(
            date=date_filter,
            quadrant=quadrant_filter if quadrant_filter != 'all' else None,
            confidence=confidence_filter if confidence_filter != 'all' else None
        )
        data = enrich_records_with_trend_fields(data, DEFAULT_CFG)
        return jsonify(data)
    
    except Exception as e:
        return jsonify([])


@app.route('/api/records/<timestamp>/<symbol>', methods=['DELETE'])
def delete_record(timestamp, symbol):
    """åˆ é™¤å•æ¡è®°å½•"""
    try:
        deleted = records_repo.delete_record(timestamp, symbol)
        if not deleted:
            return jsonify({'error': 'æœªæ‰¾åˆ°è¯¥è®°å½•'}), 404
        return jsonify({'message': 'åˆ é™¤æˆåŠŸ'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/records/date/<date>', methods=['DELETE'])
def delete_records_by_date(date):
    """æŒ‰æ—¥æœŸåˆ é™¤è®°å½•"""
    try:
        deleted_count = records_repo.delete_by_date(date)
        if deleted_count == 0:
            return jsonify({'error': 'æœªæ‰¾åˆ°è¯¥æ—¥æœŸçš„è®°å½•'}), 404
        return jsonify({'message': f'æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/records/all', methods=['DELETE'])
def delete_all_records():
    """åˆ é™¤æ‰€æœ‰è®°å½•"""
    try:
        records_repo.delete_all()
        return jsonify({'message': 'æ‰€æœ‰æ•°æ®å·²åˆ é™¤'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/dates', methods=['GET'])
def get_dates():
    """è·å–æ‰€æœ‰æ—¥æœŸ"""
    try:
        dates = records_repo.list_dates()
        return jsonify(dates)
    except Exception as e:
        return jsonify([]), 200


@app.route('/api/config', methods=['GET'])
def get_config():
    """è·å–å½“å‰é…ç½®"""
    return jsonify(DEFAULT_CFG)


@app.route('/api/config', methods=['POST'])
def update_config():
    """æ›´æ–°é…ç½® (è¿è¡Œæ—¶)"""
    try:
        new_cfg = request.json
        DEFAULT_CFG.update(new_cfg)
        return jsonify({'message': 'é…ç½®æ›´æ–°æˆåŠŸ', 'config': DEFAULT_CFG})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/analyze/stream', methods=['POST'])
def analyze_stream():
    """
    æµå¼åˆ†ææ¥å£ - ä¿®å¤ç‰ˆæœ¬
    
    ä¿®å¤å†…å®¹ï¼š
    1. æµå¼æ¨é€åˆ†æè¿›åº¦
    2. âœ¨ NEW: æ·»åŠ 18:00æ—¶é—´é™åˆ¶é€»è¾‘
    
    POST /api/analyze/stream?ignore_earnings=false
    Body: { "records": [...] }
    
    è¿”å› Server-Sent Events (SSE) æµ
    """
    def generate():
        try:
            ignore_earnings = request.args.get('ignore_earnings', 'false').lower() == 'true'
            records = request.json.get('records', [])
            
            if not isinstance(records, list) or len(records) == 0:
                yield f"data: {json.dumps({'type': 'error', 'error': 'æ•°æ®æ ¼å¼é”™è¯¯'})}\n\n"
                return
            
            # æå–æ‰€æœ‰ symbol
            symbols = list(set(r.get('symbol', '') for r in records if r.get('symbol')))
            num_symbols = len(symbols)
            
            # ğŸŸ¢ å‘é€åˆå§‹åŒ–æ¶ˆæ¯
            yield f"data: {json.dumps({'type': 'init', 'total': num_symbols})}\n\n"
            
            # âœ¨ NEW: æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ç›˜åæ•°æ®è·å–
            skip_oi = should_skip_oi_fetch()
            skip_iv = skip_oi
            
            # åˆå§‹åŒ– IV / OI æ•°æ®
            iv_data = {}
            oi_data = {}

            # åªè·å–ä¸€æ¬¡ VIXï¼Œé¿å…éšæ ‡çš„å¾ªç¯æ‰“å°
            vix_value = get_vix_with_fallback(default=18.0)
            
            if skip_iv:
                print(f"\nâ° å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ IV æ•°æ®è·å–")
            else:
                iv_estimated_time = estimate_iv_fetch_time(num_symbols)
                iv_estimated_minutes = iv_estimated_time / 60.0
                print(f"\n{'='*60}")
                print("ğŸ“Š IV æ•°æ®è·å–é…ç½®:")
                print(f"   - æ ‡çš„æ•°é‡: {num_symbols}")
                print(f"   - é¢„è®¡è€—æ—¶: {iv_estimated_minutes:.1f} åˆ†é’Ÿ")
                print(f"{'='*60}\n")
                iv_data = fetch_iv_terms(symbols)

            if skip_oi:
                # âœ¨ è·³è¿‡ OI è·å–
                info_msg = {'type': 'info', 'message': 'å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ OI æ•°æ®è·å–', 'workers': 0, 'estimated_time': 0}
                yield f"data: {json.dumps(info_msg)}\n\n"
                
                complete_msg = {'type': 'oi_complete', 'success': 0, 'skipped': True}
                yield f"data: {json.dumps(complete_msg)}\n\n"
            else:
                oi_input = {
                    symbol: iv_data.get(symbol).total_oi if iv_data.get(symbol) else None
                    for symbol in symbols
                }
                oi_data = batch_compute_delta_oi(oi_input)
                complete_data = {
                    'type': 'oi_complete',
                    'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                    'skipped': False
                }
                yield f"data: {json.dumps(complete_data)}\n\n"
            
            # ğŸŸ¢ å¼€å§‹åˆ†ææ•°æ®
            results = []
            errors = []
            processed_symbols = set()
            
            for i, record in enumerate(records):
                try:
                    symbol = record.get('symbol', '')
                    
                    # æ³¨å…¥ IV æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                    iv_result = iv_data.get(symbol)
                    if iv_result:
                        if iv_result.iv7 is not None:
                            record['IV7'] = iv_result.iv7
                        if iv_result.iv30 is not None:
                            record['IV30'] = iv_result.iv30
                        if iv_result.iv60 is not None:
                            record['IV60'] = iv_result.iv60
                        if iv_result.iv90 is not None:
                            record['IV90'] = iv_result.iv90

                    # æ³¨å…¥ OI æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                    if not skip_oi and symbol in oi_data:
                        current_oi, delta_oi = oi_data[symbol]
                        record['oi_info'] = {
                            'total_oi': current_oi,
                            'delta_oi_1d': delta_oi,
                            'data_available': (current_oi is not None or delta_oi is not None),
                        }
                        if current_oi is not None:
                            record['TotalOI'] = current_oi
                        if delta_oi is not None:
                            record['Î”OI_1D'] = delta_oi
                    
                    # è·å–å†å²è¯„åˆ†
                    history_scores = get_history_scores(symbol)
                    
                    # âœ¨ NEW: ä¼ é€’ skip_oi æ ‡å¿—
                    analysis = calculate_analysis(
                        record,
                        ignore_earnings=ignore_earnings,
                        history_scores=history_scores,
                        skip_oi=skip_oi,  # âœ¨ æ–°å¢å‚æ•°
                        vix_value=vix_value
                    )
                    results.append(analysis)
                    
                    # è®°å½•å”¯ä¸€æ ‡çš„å®Œæˆæ•°é‡
                    if symbol:
                        processed_symbols.add(symbol)
                    
                    # ğŸŸ¢ å‘é€å•æ¡åˆ†æå®Œæˆè¿›åº¦ï¼ˆæŒ‰å”¯ä¸€æ ‡çš„è®¡æ•°ï¼Œä¸å‰ç«¯æ€»æ•°ä¸€è‡´ï¼‰
                    analyze_progress = {
                        'type': 'analyze_progress', 
                        'completed': len(processed_symbols), 
                        'total': num_symbols,
                        'symbol': symbol,
                        'percentage': round(100 * len(processed_symbols) / num_symbols, 1) if num_symbols else 100.0
                    }
                    yield f"data: {json.dumps(analyze_progress)}\n\n"
                    # æ–¹ä¾¿è¯Šæ–­æµå¼è¿›åº¦
                    print(f"[SSE] analyze_progress {len(processed_symbols)}/{num_symbols} {symbol}")
                
                except Exception as e:
                    error_msg = f"æ ‡çš„ {record.get('symbol', f'#{i+1}')} åˆ†æå¤±è´¥: {str(e)}"
                    errors.append(error_msg)
            
            # ä¿å­˜æ•°æ®
            if results:
                records_repo.upsert_daily_latest(results)
            
            # ğŸŸ¢ å‘é€å®Œæˆæ¶ˆæ¯
            message = f'æˆåŠŸåˆ†æ {len(results)} ä¸ªæ ‡çš„'
            if errors:
                message += f',{len(errors)} ä¸ªå¤±è´¥'
            if skip_oi:
                message += ' (å·²è·³è¿‡ OI æ•°æ®è·å–)'
            
            final_data = {
                'type': 'complete',
                'message': message,
                'results': results,
                'errors': errors if errors else None,
                'oi_stats': {
                    'total': num_symbols,
                    'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                    'with_delta': sum(1 for s in symbols if oi_data.get(s, (None, None))[1] is not None),
                    'skipped': skip_oi  # âœ¨ æ–°å¢æ ‡å¿—
                }
            }
            
            yield f"data: {json.dumps(final_data)}\n\n"
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive'
        }
    )


@app.route('/api/vix/info', methods=['GET'])
def get_vix_cache_info():
    """
    è·å– VIX ç¼“å­˜çŠ¶æ€ï¼ˆè¯Šæ–­ç”¨ï¼‰
    
    GET /api/vix/info
    
    å“åº”ç¤ºä¾‹:
        {
            "current_vix": 18.52,
            "cached_vix": 18.52,
            "cache_age_seconds": 300,
            "cache_valid": true,
            "cache_file": "vix_cache.json",
            "cache_exists": true
        }
    """
    try:
        info = get_vix_info()
        return jsonify(info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/vix/clear', methods=['POST'])
def clear_vix_cache_endpoint():
    """
    æ¸…é™¤ VIX ç¼“å­˜ï¼ˆå¼ºåˆ¶åˆ·æ–°ç”¨ï¼‰
    
    POST /api/vix/clear
    
    å“åº”ç¤ºä¾‹:
        {
            "message": "VIX cache cleared successfully"
        }
    """
    try:
        clear_vix_cache()
        return jsonify({'message': 'VIX cache cleared successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# æ³¨å†Œ swing é¡¹ç›®çš„ API æ‰©å±•
from api_extension import register_bridge_api, register_swing_api
register_swing_api(app)
register_bridge_api(app, DEFAULT_CFG)


if __name__ == '__main__':
    print(">>>>>>>>> ÏƒÂ² <<<<<<<<<<<<<")
    
    try:
        debug_mode = os.environ.get("FLASK_DEBUG", "0") == "1"
        # é»˜è®¤å…³é—­ reloaderï¼Œé¿å…é•¿ä»»åŠ¡è¢«çƒ­é‡è½½ä¸­æ–­ï¼›éœ€è¦è°ƒè¯•æ—¶æ‰‹åŠ¨å¼€å¯ç¯å¢ƒå˜é‡
        app.run(debug=debug_mode, use_reloader=False, host='0.0.0.0', port=8668)
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
