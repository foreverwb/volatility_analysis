"""
æœŸæƒç­–ç•¥é‡åŒ–åˆ†æç³»ç»Ÿ v2.4.0
Flask ä¸»åº”ç”¨å…¥å£

âœ¨ v2.4.0 æ–°å¢ä¼˜åŒ–ï¼š
1. ä¼˜åŒ–æ•°æ®è·å–é¡ºåºï¼šå…ˆ OIï¼ˆå¿«ï¼‰â†’ å IVï¼ˆæ…¢ï¼‰
2. IV è·å–æ”¹ä¸ºå¹¶å‘æ¨¡å¼
3. å¢å¼ºæ—¥å¿—å¯è¯»æ€§
"""
from flask import Flask, render_template, request, jsonify, send_from_directory, Response, stream_with_context
import json
import os
from typing import List, Dict, Any
from datetime import datetime, timedelta, time
from collections import defaultdict
from queue import Queue, Empty
import threading
from core.market_data import get_vix_info, clear_vix_cache

from core import (
    DEFAULT_CFG,
    calculate_analysis
)
from core.oi_fetcher import batch_fetch_oi, auto_tune_workers, estimate_fetch_time
from core.futu_option_iv import fetch_iv_term_structure
app = Flask(__name__)

DATA_FILE = 'analysis_records.json'

# =========================
# æ—¶é—´åˆ¤æ–­å·¥å…·å‡½æ•°
# =========================
def should_skip_oi_fetch() -> bool:
    """
    åˆ¤æ–­å½“å‰æ—¶é—´æ˜¯å¦åº”è·³è¿‡ OI æ•°æ®è·å–
    
    è§„åˆ™: åŒ—äº¬æ—¶é—´ 18:00 ä¹‹å‰è·³è¿‡
    
    Returns:
        True if å½“å‰æ—¶é—´ < 18:00 CST
    """
    import pytz
    
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now_beijing = datetime.now(beijing_tz)
    
    cutoff_time = time(18, 0, 0)
    
    return now_beijing.time() < cutoff_time


# =========================
# æ•°æ®æŒä¹…åŒ–
# =========================
def load_data() -> List[Dict[str, Any]]:
    """åŠ è½½åˆ†æè®°å½•"""
    if not os.path.exists(DATA_FILE):
        return []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if not content:
                return []
            data = json.loads(content)
            return data if isinstance(data, list) else []
    except (json.JSONDecodeError, Exception) as e:
        print(f"è­¦å‘Š: è¯»å– {DATA_FILE} å¤±è´¥: {e}")
        return []


def save_data(data: List[Dict[str, Any]]):
    """ä¿å­˜åˆ†æè®°å½•"""
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def get_history_scores(symbol: str, n_days: int = 5, as_of_date: str = None) -> List[float]:
    """
    è·å–æŒ‡å®šæ ‡çš„çš„å†å²æ–¹å‘è¯„åˆ†ï¼ˆç”¨äºè·¨æœŸä¸€è‡´æ€§è®¡ç®—ï¼‰
    
    Args:
        symbol: æ ‡çš„ä»£ç ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
        n_days: éœ€è¦çš„å†å²å¤©æ•°ï¼ˆé»˜è®¤ 5 å¤©ï¼‰
        as_of_date: æˆªæ­¢æ—¥æœŸï¼ˆæ ¼å¼: YYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
    Returns:
        å†å²è¯„åˆ†åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åºï¼Œæœ€æ–°åœ¨å‰ï¼‰
    """
    records = load_data()
    symbol_upper = symbol.upper()
    
    symbol_records = [
        r for r in records 
        if r.get('symbol', '').upper() == symbol_upper
    ]
    
    if not symbol_records:
        return []
    
    if as_of_date is None:
        as_of = datetime.now()
    else:
        try:
            as_of = datetime.strptime(as_of_date, '%Y-%m-%d')
        except ValueError:
            as_of = datetime.now()
    
    records_by_date = defaultdict(list)
    
    for r in symbol_records:
        timestamp = r.get('timestamp', '')
        if not timestamp:
            continue
        
        try:
            date_str = timestamp.split(' ')[0]
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            
            if dt <= as_of:
                records_by_date[date_str].append(r)
        except (ValueError, IndexError):
            continue
    
    daily_latest = {}
    for date_str, day_records in records_by_date.items():
        day_records.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        daily_latest[date_str] = day_records[0]
    
    sorted_dates = sorted(daily_latest.keys(), reverse=True)
    
    history_scores = []
    for date_str in sorted_dates[:n_days]:
        record = daily_latest[date_str]
        score = record.get('direction_score', 0)
        history_scores.append(float(score))
    
    return history_scores


# =========================
# Flask è·¯ç”±
# =========================
@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory('static', filename)


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """
    åˆ†ææ•°æ®æ¥å£ - v2.4.0 ä¼˜åŒ–ç‰ˆ
    
    POST /api/analyze?ignore_earnings=false
    Body: { "records": [...] }
    
    âœ¨ ä¼˜åŒ–: å…ˆè·å– OIï¼ˆå¿«ï¼‰â†’ å†è·å– IVï¼ˆæ…¢ï¼‰
    """
    try:
        ignore_earnings = request.args.get('ignore_earnings', 'false').lower() == 'true'
        records = request.json.get('records', [])
        
        if not isinstance(records, list):
            return jsonify({'error': 'æ•°æ®æ ¼å¼é”™è¯¯,éœ€è¦æ˜¯åˆ—è¡¨'}), 400
        
        if len(records) == 0:
            return jsonify({'error': 'æ•°æ®åˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
        
        skip_oi = should_skip_oi_fetch()
        
        symbols = list(set(r.get('symbol', '') for r in records if r.get('symbol')))
        num_symbols = len(symbols)
        
        # ========== âœ¨ ä¼˜åŒ–ï¼šå…ˆå¿«åæ…¢ ==========
        
        # 1ï¸âƒ£ å…ˆè·å– OI æ•°æ®ï¼ˆå¿«ï¼Œä¸”ç”¨æˆ·æœ€å…³å¿ƒï¼‰
        oi_data = {}
        
        if skip_oi:
            print(f"\nâ° å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ OI æ•°æ®è·å–")
        else:
            auto_tuned_workers = auto_tune_workers(num_symbols)
            estimated_time = estimate_fetch_time(num_symbols, auto_tuned_workers)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š OI æ•°æ®è·å–é…ç½®:")
            print(f"   - æ ‡çš„æ•°é‡: {num_symbols}")
            print(f"   - å¹¶å‘çº¿ç¨‹: {auto_tuned_workers}")
            print(f"   - é¢„è®¡è€—æ—¶: {estimated_time:.1f}s")
            print(f"{'='*60}\n")
            
            oi_data = batch_fetch_oi(symbols, max_workers=auto_tuned_workers)
        
        # 2ï¸âƒ£ å†è·å– IV æ•°æ®ï¼ˆæ…¢ï¼Œä½†å¯ä»¥å¹¶å‘ï¼‰
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ IV æ•°æ®è·å–é…ç½®:")
        print(f"   - æ ‡çš„æ•°é‡: {num_symbols}")
        print(f"   - å¹¶å‘çº¿ç¨‹: 5 (Futu é™æµä¿æŠ¤)")
        print(f"{'='*60}\n")
        
        iv_term_data = fetch_iv_term_structure(
            symbols,
            max_workers=5  # Futu API é™æµï¼Œå»ºè®®ä¸è¶…è¿‡5
        )
        
        # 3ï¸âƒ£ åˆ†ææ•°æ®
        results = []
        errors = []
        
        for i, record in enumerate(records):
            try:
                symbol = record.get('symbol', '')
                symbol_upper = symbol.upper()

                # æ³¨å…¥ IV æ•°æ®
                if symbol_upper in iv_term_data:
                    iv_values = iv_term_data[symbol_upper]
                    for key, value in iv_values.items():
                        if value is not None:
                            record[key] = value
                    if iv_values.get("IV_90D") is not None:
                        record["IV90"] = iv_values["IV_90D"]
                
                # æ³¨å…¥ OI æ•°æ®
                if not skip_oi and symbol in oi_data:
                    current_oi, delta_oi = oi_data[symbol]
                    if delta_oi is not None:
                        record['Î”OI_1D'] = delta_oi
                        
                history_scores = get_history_scores(symbol)
                
                analysis = calculate_analysis(
                    record,
                    ignore_earnings=ignore_earnings,
                    history_scores=history_scores,
                    skip_oi=skip_oi
                )
                results.append(analysis)
            except Exception as e:
                error_msg = f"æ ‡çš„ {record.get('symbol', f'#{i+1}')} åˆ†æå¤±è´¥: {str(e)}"
                errors.append(error_msg)
                print(f"é”™è¯¯: {error_msg}")
        
        # 4ï¸âƒ£ ä¿å­˜æ•°æ®
        if results:
            all_data = load_data()
            new_records_map = {}
            for r in results:
                date = r['timestamp'].split(' ')[0]
                symbol = r['symbol']
                key = (date, symbol)
                new_records_map[key] = r
            
            filtered_old_data = []
            for old_record in all_data:
                date = old_record.get('timestamp', '').split(' ')[0]
                symbol = old_record.get('symbol', '')
                key = (date, symbol)
                if key not in new_records_map:
                    filtered_old_data.append(old_record)
            
            all_data = filtered_old_data + results
            save_data(all_data)
        
        message = f'æˆåŠŸåˆ†æ {len(results)} ä¸ªæ ‡çš„'
        if errors:
            message += f',{len(errors)} ä¸ªå¤±è´¥'
        
        if skip_oi:
            message += ' (å·²è·³è¿‡ OI æ•°æ®è·å–)'
        
        return jsonify({
            'message': message,
            'results': results,
            'errors': errors if errors else None,
            'oi_stats': {
                'total': num_symbols,
                'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                'with_delta': sum(1 for s in symbols if oi_data.get(s, (None, None))[1] is not None),
                'skipped': skip_oi
            }
        }), 201
    
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/records', methods=['GET'])
def get_records():
    """è·å–åˆ†æè®°å½•"""
    try:
        data = load_data()
        if not isinstance(data, list):
            return jsonify([])
        
        date_filter = request.args.get('date')
        quadrant_filter = request.args.get('quadrant')
        confidence_filter = request.args.get('confidence')
        
        filtered_data = data
        
        if date_filter:
            filtered_data = [d for d in filtered_data if d.get('timestamp', '').startswith(date_filter)]
        
        if quadrant_filter and quadrant_filter != 'all':
            filtered_data = [d for d in filtered_data if d.get('quadrant') == quadrant_filter]
        
        if confidence_filter and confidence_filter != 'all':
            filtered_data = [d for d in filtered_data if d.get('confidence') == confidence_filter]
        
        return jsonify(filtered_data)
    
    except Exception as e:
        return jsonify([])


@app.route('/api/records/<timestamp>/<symbol>', methods=['DELETE'])
def delete_record(timestamp, symbol):
    """åˆ é™¤å•æ¡è®°å½•"""
    try:
        data = load_data()
        original_length = len(data)
        data = [d for d in data if not (d['timestamp'] == timestamp and d['symbol'] == symbol)]
        if len(data) == original_length:
            return jsonify({'error': 'æœªæ‰¾åˆ°è¯¥è®°å½•'}), 404
        save_data(data)
        return jsonify({'message': 'åˆ é™¤æˆåŠŸ'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/records/date/<date>', methods=['DELETE'])
def delete_records_by_date(date):
    """æŒ‰æ—¥æœŸåˆ é™¤è®°å½•"""
    try:
        data = load_data()
        original_length = len(data)
        data = [d for d in data if not d.get('timestamp', '').startswith(date)]
        deleted_count = original_length - len(data)
        if deleted_count == 0:
            return jsonify({'error': 'æœªæ‰¾åˆ°è¯¥æ—¥æœŸçš„è®°å½•'}), 404
        save_data(data)
        return jsonify({'message': f'æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/records/all', methods=['DELETE'])
def delete_all_records():
    """åˆ é™¤æ‰€æœ‰è®°å½•"""
    try:
        save_data([])
        return jsonify({'message': 'æ‰€æœ‰æ•°æ®å·²åˆ é™¤'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/dates', methods=['GET'])
def get_dates():
    """è·å–æ‰€æœ‰æ—¥æœŸ"""
    try:
        data = load_data()
        dates = sorted(set(d.get('timestamp', '')[:10] for d in data if d.get('timestamp')), reverse=True)
        return jsonify(dates)
    except Exception as e:
        return jsonify([]), 200


@app.route('/api/config', methods=['GET'])
def get_config():
    """è·å–å½“å‰é…ç½®"""
    return jsonify(DEFAULT_CFG)


@app.route('/api/config', methods=['POST'])
def update_config():
    """æ›´æ–°é…ç½® (è¿è¡Œæ—¶)"""
    try:
        new_cfg = request.json
        DEFAULT_CFG.update(new_cfg)
        return jsonify({'message': 'é…ç½®æ›´æ–°æˆåŠŸ', 'config': DEFAULT_CFG})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/analyze/stream', methods=['POST'])
def analyze_stream():
    """
    æµå¼åˆ†ææ¥å£ - v2.4.0 ä¼˜åŒ–ç‰ˆ
    
    âœ¨ ä¼˜åŒ–: å…ˆè·å– OIï¼ˆå¿«ï¼‰â†’ å†è·å– IVï¼ˆæ…¢ï¼‰
    
    POST /api/analyze/stream?ignore_earnings=false
    Body: { "records": [...] }
    
    è¿”å› Server-Sent Events (SSE) æµ
    """
    def generate():
        try:
            ignore_earnings = request.args.get('ignore_earnings', 'false').lower() == 'true'
            records = request.json.get('records', [])
            
            if not isinstance(records, list) or len(records) == 0:
                yield f"data: {json.dumps({'type': 'error', 'error': 'æ•°æ®æ ¼å¼é”™è¯¯'})}\n\n"
                return
            
            symbols = list(set(r.get('symbol', '') for r in records if r.get('symbol')))
            num_symbols = len(symbols)
            
            yield f"data: {json.dumps({'type': 'init', 'total': num_symbols})}\n\n"
            
            skip_oi = should_skip_oi_fetch()
            
            # ========== 1ï¸âƒ£ å…ˆè·å– OI æ•°æ® ==========
            oi_data = {}
            
            if skip_oi:
                info_msg = {'type': 'info', 'message': 'å½“å‰æ—¶é—´æ—©äº 18:00 CSTï¼Œè·³è¿‡ OI æ•°æ®è·å–', 'workers': 0, 'estimated_time': 0}
                yield f"data: {json.dumps(info_msg)}\n\n"
                
                complete_msg = {'type': 'oi_complete', 'success': 0, 'skipped': True}
                yield f"data: {json.dumps(complete_msg)}\n\n"
            else:
                auto_tuned_workers = auto_tune_workers(num_symbols)
                estimated_time = estimate_fetch_time(num_symbols, auto_tuned_workers)
                
                info_data = {'type': 'info', 'workers': auto_tuned_workers, 'estimated_time': estimated_time}
                yield f"data: {json.dumps(info_data)}\n\n"
                
                progress_queue = Queue()
                fetch_error = None
                
                def fetch_oi_task():
                    nonlocal oi_data, fetch_error
                    try:
                        oi_data = batch_fetch_oi(
                            symbols, 
                            max_workers=auto_tuned_workers,
                            progress_queue=progress_queue
                        )
                    except Exception as e:
                        fetch_error = str(e)
                        progress_queue.put({'type': 'error', 'error': str(e)})
                
                fetch_thread = threading.Thread(target=fetch_oi_task)
                fetch_thread.start()
                
                oi_fetch_complete = False
                
                while not oi_fetch_complete or not progress_queue.empty():
                    try:
                        progress_data = progress_queue.get(timeout=0.5)
                        
                        if progress_data.get('type') == 'complete':
                            oi_fetch_complete = True
                            complete_data = {
                                'type': 'oi_complete', 
                                'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                                'skipped': False
                            }
                            yield f"data: {json.dumps(complete_data)}\n\n"
                            break
                        
                        elif progress_data.get('type') == 'error':
                            yield f"data: {json.dumps(progress_data)}\n\n"
                            return
                        
                        else:
                            progress_msg = {
                                'type': 'progress',
                                'completed': progress_data['completed'],
                                'total': progress_data['total'],
                                'symbol': progress_data['symbol'],
                                'percentage': round((progress_data['completed'] / progress_data['total']) * 100, 1)
                            }
                            yield f"data: {json.dumps(progress_msg)}\n\n"
                    
                    except Empty:
                        if not fetch_thread.is_alive():
                            oi_fetch_complete = True
                            break
                        continue
                
                fetch_thread.join(timeout=5)
                
                if fetch_error:
                    yield f"data: {json.dumps({'type': 'error', 'error': fetch_error})}\n\n"
                    return
            
            # ========== 2ï¸âƒ£ å†è·å– IV æ•°æ® ==========
            yield f"data: {json.dumps({'type': 'info', 'message': 'å¼€å§‹è·å– IV æ•°æ®...'})}\n\n"
            
            iv_term_data = fetch_iv_term_structure(symbols, max_workers=5)
            
            yield f"data: {json.dumps({'type': 'iv_complete'})}\n\n"
            
            # ========== 3ï¸âƒ£ åˆ†ææ•°æ® ==========
            results = []
            errors = []
            
            for i, record in enumerate(records):
                try:
                    symbol = record.get('symbol', '')
                    symbol_upper = symbol.upper()

                    if symbol_upper in iv_term_data:
                        iv_values = iv_term_data[symbol_upper]
                        for key, value in iv_values.items():
                            if value is not None:
                                record[key] = value
                        if iv_values.get("IV_90D") is not None:
                            record["IV90"] = iv_values["IV_90D"]
                    
                    if not skip_oi and symbol in oi_data:
                        current_oi, delta_oi = oi_data[symbol]
                        if delta_oi is not None:
                            record['Î”OI_1D'] = delta_oi
                    
                    history_scores = get_history_scores(symbol)
                    
                    analysis = calculate_analysis(
                        record,
                        ignore_earnings=ignore_earnings,
                        history_scores=history_scores,
                        skip_oi=skip_oi
                    )
                    results.append(analysis)
                    
                    if i % 5 == 0 or i == len(records) - 1:
                        analyze_progress = {
                            'type': 'analyze_progress', 
                            'completed': i + 1, 
                            'total': len(records)
                        }
                        yield f"data: {json.dumps(analyze_progress)}\n\n"
                    
                except Exception as e:
                    error_msg = f"æ ‡çš„ {record.get('symbol', f'#{i+1}')} åˆ†æå¤±è´¥: {str(e)}"
                    errors.append(error_msg)
            
            if results:
                all_data = load_data()
                new_records_map = {}
                for r in results:
                    date = r['timestamp'].split(' ')[0]
                    symbol = r['symbol']
                    key = (date, symbol)
                    new_records_map[key] = r
                
                filtered_old_data = []
                for old_record in all_data:
                    date = old_record.get('timestamp', '').split(' ')[0]
                    symbol = old_record.get('symbol', '')
                    key = (date, symbol)
                    if key not in new_records_map:
                        filtered_old_data.append(old_record)
                
                all_data = filtered_old_data + results
                save_data(all_data)
            
            message = f'æˆåŠŸåˆ†æ {len(results)} ä¸ªæ ‡çš„'
            if errors:
                message += f',{len(errors)} ä¸ªå¤±è´¥'
            if skip_oi:
                message += ' (å·²è·³è¿‡ OI æ•°æ®è·å–)'
            
            final_data = {
                'type': 'complete',
                'message': message,
                'results': results,
                'errors': errors if errors else None,
                'oi_stats': {
                    'total': num_symbols,
                    'success': sum(1 for s in symbols if oi_data.get(s, (None, None))[0] is not None),
                    'with_delta': sum(1 for s in symbols if oi_data.get(s, (None, None))[1] is not None),
                    'skipped': skip_oi
                }
            }
            
            yield f"data: {json.dumps(final_data)}\n\n"
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive'
        }
    )


@app.route('/api/vix/info', methods=['GET'])
def get_vix_cache_info():
    """è·å– VIX ç¼“å­˜çŠ¶æ€"""
    try:
        info = get_vix_info()
        return jsonify(info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/vix/clear', methods=['POST'])
def clear_vix_cache_endpoint():
    """æ¸…é™¤ VIX ç¼“å­˜"""
    try:
        clear_vix_cache()
        return jsonify({'message': 'VIX cache cleared successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# æ³¨å†Œ swing é¡¹ç›®çš„ API æ‰©å±•
from api_extension import register_swing_api
register_swing_api(app)


if __name__ == '__main__':
    print("\n" + "="*80)
    print("æœŸæƒç­–ç•¥é‡åŒ–åˆ†æç³»ç»Ÿ v2.4.0")
    print("="*80)
    print("\nğŸ“¡ API ç«¯ç‚¹:")
    print("   POST /api/analyze         - æ ‡å‡†åˆ†ææ¥å£")
    print("   POST /api/analyze/stream  - æµå¼åˆ†ææ¥å£ï¼ˆæ¨èï¼‰")
    print("   GET  /api/swing/params/<symbol>")
    print("   POST /api/swing/params/batch")
    print("\nâœ¨ v2.4.0 ä¼˜åŒ–:")
    print("   â€¢ IV æ•°æ®å¹¶å‘è·å–ï¼ˆ5çº¿ç¨‹ï¼‰")
    print("   â€¢ ä¼˜åŒ–è·å–é¡ºåºï¼šå…ˆ OIï¼ˆå¿«ï¼‰â†’ å IVï¼ˆæ…¢ï¼‰")
    print("   â€¢ ç²¾ç®€æ—¥å¿—è¾“å‡ºï¼Œå¢å¼ºå¯è¯»æ€§")
    print("\nâ° æ—¶é—´é™åˆ¶:")
    print("   â€¢ 18:00 CST ä¹‹å‰è·³è¿‡ OI æ•°æ®è·å–")
    print("="*80 + "\n")
    
    try:
        app.run(debug=True, host='0.0.0.0', port=8668)
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()