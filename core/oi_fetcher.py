"""
æœªå¹³ä»“åˆçº¦ (Open Interest) æ•°æ®è·å–æ¨¡å— - v2.3.3 å¤šçº¿ç¨‹ä¼˜åŒ–ç‰ˆ
Data Source: Yahoo Finance (yfinance)
"""
import yfinance as yf
import pandas as pd
from typing import Optional, Tuple, Dict, List, Callable
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import os
import time
import threading
from queue import Queue, Empty

OI_CACHE_FILE = "oi_cache.json"
CACHE_LOCK = threading.Lock()  # ç¼“å­˜æ–‡ä»¶é”

# ========== é…ç½®å‚æ•° ==========
DEFAULT_MAX_WORKERS = 8        # é»˜è®¤å¹¶å‘çº¿ç¨‹æ•°
DEFAULT_TIMEOUT = 30           # å•ä¸ªè¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
MAX_RETRIES = 2                # å¤±è´¥é‡è¯•æ¬¡æ•°
RETRY_DELAY = 1                # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰


def fetch_total_oi(symbol: str, timeout: int = DEFAULT_TIMEOUT) -> Optional[int]:
    """
    è·å–æ ‡çš„çš„æ€»æœªå¹³ä»“åˆçº¦é‡ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
    
    Args:
        symbol: æ ‡çš„ä»£ç 
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        æ€» OI é‡ï¼Œå¤±è´¥è¿”å› None
    """
    try:
        ticker = yf.Ticker(symbol)
        expirations = ticker.options
        
        if not expirations:
            print(f"âš  {symbol}: No options data")
            return None
        
        total_oi = 0
        
        for exp in expirations:
            try:
                opt_chain = ticker.option_chain(exp)
                total_oi += opt_chain.calls['openInterest'].sum()
                total_oi += opt_chain.puts['openInterest'].sum()
            except Exception as e:
                print(f"âš  {symbol} exp {exp}: {str(e)[:50]}")
                continue
        
        return int(total_oi) if total_oi > 0 else None
    
    except Exception as e:
        print(f"âŒ {symbol}: {str(e)[:80]}")
        return None


def load_oi_cache() -> dict:
    """åŠ è½½ OI ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with CACHE_LOCK:
        if not os.path.exists(OI_CACHE_FILE):
            return {}
        
        try:
            with open(OI_CACHE_FILE, 'r') as f:
                return json.load(f)
        except:
            return {}


def save_oi_cache(cache: dict):
    """ä¿å­˜ OI ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with CACHE_LOCK:
        try:
            with open(OI_CACHE_FILE, 'w') as f:
                json.dump(cache, f, indent=2)
        except Exception as e:
            print(f"âš  Failed to save OI cache: {e}")


def get_oi_with_delta(symbol: str) -> Tuple[Optional[int], Optional[int]]:
    """
    è·å–å½“å‰ OI åŠ Î”OI_1D
    
    Args:
        symbol: æ ‡çš„ä»£ç 
        
    Returns:
        (current_oi, delta_oi_1d)
    """
    # 1. è·å–å½“å‰ OI
    current_oi = fetch_total_oi(symbol)
    if current_oi is None:
        return (None, None)
    
    # 2. åŠ è½½ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    cache = load_oi_cache()
    
    today = datetime.now().strftime('%Y-%m-%d')
    
    # 3. æŸ¥æ‰¾æœ€è¿‘çš„å†å²æ•°æ®ï¼ˆè€ƒè™‘å‘¨æœ«/èŠ‚å‡æ—¥ï¼‰
    symbol_cache = cache.get(symbol, {})
    yesterday_oi = None
    
    for days_ago in range(1, 8):  # æœ€å¤šå‘å‰æŸ¥æ‰¾ 7 å¤©
        past_date = (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m-%d')
        if past_date in symbol_cache:
            yesterday_oi = symbol_cache[past_date]
            break
    
    # 4. è®¡ç®— delta
    delta_oi = None
    if yesterday_oi is not None:
        delta_oi = current_oi - yesterday_oi
    
    # 5. æ›´æ–°ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    if symbol not in cache:
        cache[symbol] = {}
    
    cache[symbol][today] = current_oi
    
    # æ¸…ç†è¶…è¿‡ 7 å¤©çš„æ•°æ®
    cutoff = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    cache[symbol] = {
        date: oi for date, oi in cache[symbol].items()
        if date >= cutoff
    }
    
    save_oi_cache(cache)
    
    return (current_oi, delta_oi)


def _fetch_single_symbol(symbol: str, retry_count: int = 0) -> Tuple[str, Optional[int], Optional[int]]:
    """
    å•ä¸ª symbol çš„è·å–é€»è¾‘ï¼ˆå†…éƒ¨å‡½æ•°ï¼Œæ”¯æŒé‡è¯•ï¼‰
    
    Returns:
        (symbol, current_oi, delta_oi)
    """
    try:
        current_oi, delta_oi = get_oi_with_delta(symbol)
        return (symbol, current_oi, delta_oi)
    
    except Exception as e:
        if retry_count < MAX_RETRIES:
            print(f"âš  {symbol}: Retry {retry_count + 1}/{MAX_RETRIES}")
            time.sleep(RETRY_DELAY)
            return _fetch_single_symbol(symbol, retry_count + 1)
        else:
            print(f"âŒ {symbol}: Failed after {MAX_RETRIES} retries")
            return (symbol, None, None)


def batch_fetch_oi(
    symbols: List[str], 
    max_workers: int = DEFAULT_MAX_WORKERS,
    progress_callback: Optional[Callable[[int, int, str], None]] = None,
    progress_queue: Optional[Queue] = None  # ğŸŸ¢ æ–°å¢ï¼šçº¿ç¨‹å®‰å…¨çš„è¿›åº¦é˜Ÿåˆ—
) -> Dict[str, Tuple[Optional[int], Optional[int]]]:
    """
    æ‰¹é‡è·å–å¤šä¸ªæ ‡çš„çš„ OI æ•°æ®ï¼ˆå¤šçº¿ç¨‹å¹¶å‘ï¼‰- çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬
    
    Args:
        symbols: æ ‡çš„åˆ—è¡¨
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­è°ƒç”¨ï¼Œä¼ ç»Ÿæ–¹å¼ï¼‰
        progress_queue: è¿›åº¦é˜Ÿåˆ—ï¼ˆç”¨äº SSE æµå¼æ¨é€ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰
        
    Returns:
        {symbol: (current_oi, delta_oi_1d)}
        
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # æ–¹å¼1ï¼šä¼ ç»Ÿå›è°ƒï¼ˆé€‚ç”¨äºåŒæ­¥åœºæ™¯ï¼‰
        >>> results = batch_fetch_oi(symbols, progress_callback=on_progress)
        
        # æ–¹å¼2ï¼šé˜Ÿåˆ—æ¨¡å¼ï¼ˆé€‚ç”¨äº SSE æµå¼æ¨é€ï¼‰
        >>> progress_queue = Queue()
        >>> results = batch_fetch_oi(symbols, progress_queue=progress_queue)
        >>> while not progress_queue.empty():
        ...     progress = progress_queue.get()
        ...     yield f"data: {json.dumps(progress)}\n\n"
    """
    if not symbols:
        return {}
    
    print(f"\nğŸ“Š Starting OI fetch for {len(symbols)} symbols (max_workers={max_workers})...")
    start_time = time.time()
    
    results = {}
    completed = 0
    total = len(symbols)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_symbol = {
            executor.submit(_fetch_single_symbol, symbol): symbol 
            for symbol in symbols
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_symbol):
            symbol = future_to_symbol[future]
            
            try:
                symbol, current_oi, delta_oi = future.result(timeout=DEFAULT_TIMEOUT)
                results[symbol] = (current_oi, delta_oi)
                
                completed += 1
                
                # çŠ¶æ€è¾“å‡ºï¼ˆæ§åˆ¶å°ï¼‰
                if delta_oi is not None:
                    sign = "+" if delta_oi > 0 else ""
                    print(f"âœ“ [{completed}/{total}] {symbol}: OI={current_oi:,}, Î”OI={sign}{delta_oi:,}")
                elif current_oi is not None:
                    print(f"âš  [{completed}/{total}] {symbol}: OI={current_oi:,}, Î”OI=N/A (é¦–æ¬¡è¿è¡Œ)")
                else:
                    print(f"âŒ [{completed}/{total}] {symbol}: Failed to fetch OI")
                
                # ğŸŸ¢ çº¿ç¨‹å®‰å…¨çš„è¿›åº¦é€šçŸ¥
                progress_data = {
                    'completed': completed,
                    'total': total,
                    'symbol': symbol,
                    'current_oi': current_oi,
                    'delta_oi': delta_oi
                }
                
                # æ–¹å¼1ï¼šä½¿ç”¨é˜Ÿåˆ—ï¼ˆä¼˜å…ˆï¼Œçº¿ç¨‹å®‰å…¨ï¼‰
                if progress_queue is not None:
                    try:
                        progress_queue.put(progress_data, block=False)
                    except Exception as e:
                        print(f"âš  Warning: Failed to put progress to queue: {e}")
                
                # æ–¹å¼2ï¼šä½¿ç”¨å›è°ƒï¼ˆä¼ ç»Ÿæ–¹å¼ï¼Œéçº¿ç¨‹å®‰å…¨ï¼Œä»…é€‚ç”¨äºåŒæ­¥åœºæ™¯ï¼‰
                if progress_callback is not None:
                    try:
                        progress_callback(completed, total, symbol)
                    except Exception as e:
                        print(f"âš  Warning: Progress callback failed: {e}")
            
            except Exception as e:
                completed += 1
                print(f"âŒ [{completed}/{total}] {symbol}: {str(e)[:50]}")
                results[symbol] = (None, None)
                
                # å³ä½¿å¤±è´¥ä¹Ÿè¦é€šçŸ¥è¿›åº¦
                if progress_queue is not None:
                    try:
                        progress_queue.put({
                            'completed': completed,
                            'total': total,
                            'symbol': symbol,
                            'error': str(e)
                        }, block=False)
                    except:
                        pass
    
    elapsed = time.time() - start_time
    success_count = sum(1 for _, (oi, _) in results.items() if oi is not None)
    
    print(f"\nğŸ“Š OI fetch completed: {success_count}/{total} successful in {elapsed:.1f}s")
    print(f"   Average: {elapsed/total:.2f}s per symbol")
    
    # ğŸŸ¢ å‘é€å®Œæˆä¿¡å·åˆ°é˜Ÿåˆ—
    if progress_queue is not None:
        try:
            progress_queue.put({'type': 'complete'}, block=False)
        except:
            pass
    
    return results


# ========== æ€§èƒ½ä¼˜åŒ–å·¥å…· ==========

def estimate_fetch_time(num_symbols: int, max_workers: int = DEFAULT_MAX_WORKERS) -> float:
    """
    ä¼°ç®—æ‰¹é‡è·å–è€—æ—¶
    
    Args:
        num_symbols: æ ‡çš„æ•°é‡
        max_workers: å¹¶å‘æ•°
        
    Returns:
        é¢„è®¡è€—æ—¶ï¼ˆç§’ï¼‰
    """
    avg_time_per_symbol = 3.0  # å¹³å‡ 3 ç§’/æ ‡çš„
    batches = (num_symbols + max_workers - 1) // max_workers
    return batches * avg_time_per_symbol


def auto_tune_workers(num_symbols: int) -> int:
    """
    æ ¹æ®æ ‡çš„æ•°é‡è‡ªåŠ¨è°ƒæ•´å¹¶å‘æ•°
    
    Args:
        num_symbols: æ ‡çš„æ•°é‡
        
    Returns:
        æ¨èçš„ max_workers
    """
    if num_symbols <= 5:
        return 3
    elif num_symbols <= 15:
        return 5
    elif num_symbols <= 30:
        return 8
    else:
        return 10


# ========== è¯Šæ–­å·¥å…· ==========

def get_oi_info(symbol: str) -> dict:
    """è·å– OI æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    cache = load_oi_cache()
    symbol_cache = cache.get(symbol, {})
    
    current_oi, delta_oi = get_oi_with_delta(symbol)
    
    return {
        "symbol": symbol,
        "current_oi": current_oi,
        "delta_oi_1d": delta_oi,
        "cache_history": symbol_cache,
        "cache_file": OI_CACHE_FILE,
        "cache_exists": os.path.exists(OI_CACHE_FILE)
    }


def clear_oi_cache():
    """æ¸…é™¤ OI ç¼“å­˜"""
    with CACHE_LOCK:
        if os.path.exists(OI_CACHE_FILE):
            os.remove(OI_CACHE_FILE)
            print("âœ“ OI cache cleared")


def benchmark_performance(symbols: List[str], max_workers_list: List[int] = [1, 5, 8, 10]):
    """
    æ€§èƒ½åŸºå‡†æµ‹è¯•
    
    Args:
        symbols: æµ‹è¯•æ ‡çš„åˆ—è¡¨
        max_workers_list: è¦æµ‹è¯•çš„å¹¶å‘æ•°åˆ—è¡¨
        
    ç¤ºä¾‹ï¼š
        >>> benchmark_performance(["AAPL", "TSLA", "NVDA", "MSFT", "GOOGL"])
    """
    print(f"\nğŸ”¬ Performance Benchmark ({len(symbols)} symbols)\n")
    print(f"{'Workers':<10} {'Time (s)':<12} {'Speed':<15}")
    print("-" * 40)
    
    for workers in max_workers_list:
        start = time.time()
        batch_fetch_oi(symbols, max_workers=workers)
        elapsed = time.time() - start
        speedup = (elapsed / (elapsed / workers)) if workers > 1 else 1.0
        
        print(f"{workers:<10} {elapsed:<12.2f} {speedup:.2f}x")


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

if __name__ == "__main__":
    # ç¤ºä¾‹ 1: æ‰¹é‡è·å–
    symbols = ["AAPL", "TSLA", "NVDA", "MSFT", "GOOGL"]
    results = batch_fetch_oi(symbols, max_workers=5)
    
    # ç¤ºä¾‹ 2: å¸¦è¿›åº¦å›è°ƒ
    def progress(completed, total, symbol):
        percent = (completed / total) * 100
        print(f"Progress: {percent:.1f}%")
    
    results = batch_fetch_oi(symbols, progress_callback=progress)
    
    # ç¤ºä¾‹ 3: æ€§èƒ½æµ‹è¯•
    # benchmark_performance(symbols)